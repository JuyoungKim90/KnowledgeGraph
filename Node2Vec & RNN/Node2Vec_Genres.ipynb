{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added to use driver\n",
    "import csv\n",
    "import numpy as np\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import operator\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from LSTMTagger import LSTMTagger\n",
    "from LSTMTrain import LSTMTrain\n",
    "from LSTMEvaluation import LSTMEvaluation\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "def createembedding(file, query):\n",
    "    print('Create the edge list')\n",
    "    with driver.session() as session, open(file, \"w\") as edges_file:\n",
    "        result = session.run(query)\n",
    "\n",
    "        writer = csv.writer(edges_file, delimiter=\" \")\n",
    "\n",
    "        for row in result:\n",
    "            writer.writerow([row[\"source\"], row[\"target\"]])\n",
    "    \n",
    "def createNode2Vec(file, EMBEDDING_FILENAME, EMBEDDING_MODEL_FILENAME):   \n",
    "    # Create a graph\n",
    "    graph=nx.read_edgelist(file, create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])\n",
    "\n",
    "    # Precompute probabilities and generate walks\n",
    "    node2vec = Node2Vec(graph, dimensions=10, walk_length=3, num_walks=20, workers=4)\n",
    "\n",
    "    ## if d_graph is big enough to fit in the memory, pass temp_folder which has enough disk space\n",
    "    # Note: It will trigger \"sharedmem\" in Parallel, which will be slow on smaller graphs\n",
    "    #node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200, workers=4, temp_folder=\"/mnt/tmp_data\")\n",
    "    # Embed\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `diemnsions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "\n",
    "    # Look for most similar nodes\n",
    "    #model.wv.most_similar('2')  # Output node names are always strings\n",
    "\n",
    "    # Save embeddings for later use\n",
    "    model.wv.save_word2vec_format(EMBEDDING_FILENAME)\n",
    "\n",
    "    # Save model for later use\n",
    "    model.save(EMBEDDING_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the edge list\n"
     ]
    }
   ],
   "source": [
    
    "file = 'graph/movies.edgelist'\n",
    "EMBEDDING_FILENAME = 'emb/node2vecmov.emb'\n",
    "EMBEDDING_MODEL_FILENAME = 'emb/embdnode2vecmov.model'\n",
    "movienode2vecquery = \"\"\"\\\n",
    "        MATCH (m:Movie)--(other)\n",
    "        RETURN id(m) AS source, id(other) AS target\n",
    "        \"\"\"\n",
    "\n",
    "createembedding(file, movienode2vecquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|███████████████████████████████████████| 9980/9980 [00:00<00:00, 10788.50it/s]\n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
   
    "createNode2Vec(file, EMBEDDING_FILENAME, EMBEDDING_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the edge list\n"
     ]
    }
   ],
   "source": [
   
    "file = 'graph/users.edgelist'\n",
    "EMBEDDING_FILENAME = 'emb/node2vecuser.emb'\n",
    "EMBEDDING_MODEL_FILENAME = 'emb/embdnode2vecuser.model'\n",
    "usernode2vecquery = \"\"\"\\\n",
    "        MATCH (u:User)--(other)\n",
    "        RETURN id(u) AS source, id(other) AS target\n",
    "        \"\"\"\n",
    "createembedding(file, usernode2vecquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|███████████████████████████████████████| 6257/6257 [00:00<00:00, 26249.72it/s]\n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
   
    "createNode2Vec(file, EMBEDDING_FILENAME, EMBEDDING_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies_genres_query = \"\"\"\\\n",
    "MATCH (genre:Genre)\n",
    "WITH genre ORDER BY genre.name\n",
    "WITH collect(id(genre)) AS genres\n",
    "MATCH (m:Movie)<-[:IS_GENRE_OF]-(genre)\n",
    "WITH genres, id(m) AS source, m.embedding AS embedding, collect(id(genre)) AS target\n",
    "RETURN source, embedding, [g in genres | CASE WHEN g in target THEN 1 ELSE 0 END] AS genres\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(movies_genres_query)\n",
    "    df = pd.DataFrame([dict(row) for row in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>embedding</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0069524995, -0.0041386094, -0.005405706, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.004386477, 0.004046303, -0.006452442, -0.00...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.0076084025, 0.0017854427, 0.0066224835, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.0011135519, 0.003364261, 0.0034164581, -0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0019104508, -0.005871291, -0.0030465412, -0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                          embedding  \\\n",
       "0       1  [-0.0069524995, -0.0041386094, -0.005405706, 0...   \n",
       "1       2  [0.004386477, 0.004046303, -0.006452442, -0.00...   \n",
       "2       3  [-0.0076084025, 0.0017854427, 0.0066224835, 0....   \n",
       "3       4  [-0.0011135519, 0.003364261, 0.0034164581, -0....   \n",
       "4       5  [0.0019104508, -0.005871291, -0.0030465412, -0...   \n",
       "\n",
       "                                              genres  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What does our DataFrame look like at the moment?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The 'get_values' method is deprecated and will be removed in a future version. Use '.to_numpy()' or '.array' instead.\n",
      "  import sys\n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: The 'get_values' method is deprecated and will be removed in a future version. Use '.to_numpy()' or '.array' instead.\n",
      "  \n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "train_index = int(len(df) * 0.9)\n",
    "train_data = df[:train_index]\n",
    "test_data = df[train_index:]\n",
    "\n",
    "train_x = train_data.ix[:, \"embedding\"]\n",
    "train_x = pd.DataFrame(np.array([np.array(item) for item in train_x.values]))\n",
    "train_x.columns = [str(col) for col in train_x.columns.get_values()]\n",
    "\n",
    "train_y = train_data.ix[:, 'genres']\n",
    "\n",
    "# separate test data\n",
    "test_x = test_data.ix[:, \"embedding\"]\n",
    "test_x = pd.DataFrame(np.array([np.array(item) for item in test_x.values]))\n",
    "test_x.columns = [str(col) for col in train_x.columns.get_values()]\n",
    "\n",
    "test_y = test_data.ix[:, 'genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.feature_column import feature_column_lib\n",
    "from tensorflow.python.training import training_util\n",
    "from tensorflow.python.training.ftrl import FtrlOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a simple multi label classifier because a movie can have more than one genre associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    labels = tf.constant(np.array([np.array(item)\n",
    "                                   for item in labels.values]))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    labels = tf.constant(np.array([np.array(item)\n",
    "                                   for item in labels.values]))\n",
    "\n",
    "    features = dict(features)\n",
    "    inputs = (features, labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, config):\n",
    "    def train_op_fn(loss):\n",
    "        opt = FtrlOptimizer(learning_rate=LEARNING_RATE)\n",
    "        return opt.minimize(loss,\n",
    "                            global_step=training_util.get_global_step())\n",
    "\n",
    "    def logit_fn(features):\n",
    "        return feature_column_lib.linear_model(\n",
    "            features=features,\n",
    "            feature_columns=feature_columns,\n",
    "            units=head.logits_dimension)\n",
    "\n",
    "    return head.create_estimator_spec(\n",
    "        features=features,\n",
    "        mode=mode,\n",
    "        logits=logit_fn(features=features),\n",
    "        labels=labels,\n",
    "        train_op_fn=train_op_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_fn(df_data, num_epochs):\n",
    "        return tf.estimator.inputs.pandas_input_fn(\n",
    "            x=df_data,\n",
    "            num_epochs=num_epochs,\n",
    "           shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\meetn\\AppData\\Local\\Temp\\tmp9mijl_18\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\meetn\\\\AppData\\\\Local\\\\Temp\\\\tmp9mijl_18', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F536BFF608>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\meetn\\AppData\\Local\\Temp\\tmp9mijl_18\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0\n",
      "INFO:tensorflow:global_step/sec: 132.692\n",
      "INFO:tensorflow:loss = 0.384254, step = 100 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.249\n",
      "INFO:tensorflow:loss = 0.34120396, step = 200 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.496\n",
      "INFO:tensorflow:loss = 0.30408654, step = 300 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.262\n",
      "INFO:tensorflow:loss = 0.31698287, step = 400 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.778\n",
      "INFO:tensorflow:loss = 0.327516, step = 500 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.642\n",
      "INFO:tensorflow:loss = 0.31527647, step = 600 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.253\n",
      "INFO:tensorflow:loss = 0.30786622, step = 700 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.977\n",
      "INFO:tensorflow:loss = 0.31018418, step = 800 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.223\n",
      "INFO:tensorflow:loss = 0.29641184, step = 900 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.356\n",
      "INFO:tensorflow:loss = 0.3113544, step = 1000 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.297\n",
      "INFO:tensorflow:loss = 0.31326658, step = 1100 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.843\n",
      "INFO:tensorflow:loss = 0.330092, step = 1200 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.838\n",
      "INFO:tensorflow:loss = 0.3137629, step = 1300 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.081\n",
      "INFO:tensorflow:loss = 0.29245245, step = 1400 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.5\n",
      "INFO:tensorflow:loss = 0.2918675, step = 1500 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.736\n",
      "INFO:tensorflow:loss = 0.28057003, step = 1600 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.421\n",
      "INFO:tensorflow:loss = 0.312234, step = 1700 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.189\n",
      "INFO:tensorflow:loss = 0.34068406, step = 1800 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.052\n",
      "INFO:tensorflow:loss = 0.33517864, step = 1900 (0.489 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\meetn\\AppData\\Local\\Temp\\tmp9mijl_18\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3355544.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-26T07:23:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\meetn\\AppData\\Local\\Temp\\tmp9mijl_18\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-26-07:23:04\n",
      "INFO:tensorflow:Saving dict for global step 2000: auc = 0.75842345, auc_precision_recall = 0.2618783, average_loss = 0.30535752, global_step = 2000, loss = 0.30616823\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: C:\\Users\\meetn\\AppData\\Local\\Temp\\tmp9mijl_18\\model.ckpt-2000\n",
      "{'auc': 0.75842345, 'auc_precision_recall': 0.2618783, 'average_loss': 0.30535752, 'loss': 0.30616823, 'global_step': 2000}\n",
      "\n",
      "Test set AUC: 0.758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_columns = [tf.feature_column.numeric_column(key=key)\n",
    "                   for key in train_x.keys()]\n",
    "\n",
    "LEARNING_RATE = 0.3\n",
    "loss_reduction = tf.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
    "\n",
    "head = tf.compat.v1.estimator.MultiLabelHead(18, weight_column=None, label_vocabulary=None,loss_reduction=loss_reduction)\n",
    "\n",
    "classifier = tf.estimator.Estimator(model_fn=model_fn)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: train_input_fn(train_x, train_y, 100),\n",
    "    steps=2000)\n",
    "\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: eval_input_fn(test_x, test_y, 100))\n",
    "\n",
    "print(eval_result)\n",
    "print('\\nTest set AUC: {auc:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source                                              movie  \\\n",
      "0    2787  Decline of Western Civilization Part II: The M...   \n",
      "1    3785                                      Stolen Summer   \n",
      "2    6993             Revenge of the Nerds IV: Nerds in Love   \n",
      "\n",
      "                                           embedding  \\\n",
      "0  [8.0696545e-06, 0.0002127382, 0.00085373764, -...   \n",
      "1  [0.0045347894, -0.0042127357, 0.0063719163, -0...   \n",
      "2  [0.000993466, -0.006794362, 0.0065342835, -0.0...   \n",
      "\n",
      "                                              genres  \n",
      "0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: The 'get_values' method is deprecated and will be removed in a future version. Use '.to_numpy()' or '.array' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>-0.006944</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-0.005319</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>-0.002914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003319</td>\n",
       "      <td>-0.005768</td>\n",
       "      <td>-0.004754</td>\n",
       "      <td>-0.004165</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>-0.005927</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.003606</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>-0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>-0.006285</td>\n",
       "      <td>-0.004112</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>-0.006845</td>\n",
       "      <td>-0.002564</td>\n",
       "      <td>-0.003860</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>-0.003131</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>-0.006794</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>-0.004108</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>-0.006136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>-0.002654</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>-0.005549</td>\n",
       "      <td>-0.002012</td>\n",
       "      <td>-0.003434</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.007020</td>\n",
       "      <td>0.006649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000008  0.000213  0.000854 -0.006944  0.000104 -0.005319  0.003169   \n",
       "1  0.004535 -0.004213  0.006372 -0.005838 -0.006285 -0.004112  0.002036   \n",
       "2  0.000993 -0.006794  0.006534 -0.000412 -0.004108  0.004736 -0.004326   \n",
       "\n",
       "          7         8         9  ...        54        55        56        57  \\\n",
       "0  0.002138  0.006348 -0.002914  ... -0.003319 -0.005768 -0.004754 -0.004165   \n",
       "1 -0.000927  0.003899  0.005837  ...  0.004062 -0.006845 -0.002564 -0.003860   \n",
       "2 -0.000629  0.006575 -0.006136  ... -0.001432  0.004912 -0.002654  0.001216   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0  0.007019 -0.005927 -0.001096 -0.003606  0.007288 -0.000287  \n",
       "1  0.000222 -0.007590  0.004161 -0.003131  0.006485  0.000765  \n",
       "2 -0.005549 -0.002012 -0.003434  0.007617  0.007020  0.006649  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_query = \"\"\"\\\n",
    "MATCH (genre:Genre)\n",
    "WITH genre ORDER BY genre.name\n",
    "RETURN collect(genre.name) AS genres\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(genres_query)\n",
    "    genres = result.peek()[\"genres\"]\n",
    "\n",
    "\n",
    "movies_genres_predict_query = \"\"\"\\\n",
    "MATCH (genre:Genre)\n",
    "WITH genre ORDER BY genre.name\n",
    "WITH collect(id(genre)) AS genres\n",
    "MATCH (m:Movie)<-[:IS_GENRE_OF]-(genre)\n",
    "WITH genres, m.title AS movie, id(m) AS source, m.embedding AS embedding, collect(id(genre)) AS target\n",
    "RETURN source, movie, embedding, [g in genres | CASE WHEN g in target THEN 1 ELSE 0 END] AS genres\n",
    "ORDER BY rand()\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(movies_genres_predict_query)\n",
    "    predict_df = pd.DataFrame([dict(row) for row in result])\n",
    "    \n",
    "print(predict_df.head())\n",
    "expected_df = predict_df[[\"genres\", \"source\", \"movie\"]]\n",
    "\n",
    "predict_x = predict_df.ix[:, \"embedding\"]\n",
    "predict_x = pd.DataFrame(np.array([np.array(item) for item in predict_x.values]))\n",
    "predict_x.columns = [str(col) for col in predict_x.columns.get_values()]\n",
    "\n",
    "predict_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meetn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\meetn\\AppData\\Local\\Temp\\tmp9mijl_18\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Movie: Decline of Western Civilization Part II: The Metal Years, The\n",
      "0 Action 0.18960461\n",
      "0 Adventure 0.12896603\n",
      "0 Animation 0.054834902\n",
      "0 Children's 0.011577904\n",
      "0 Comedy 0.38235083\n",
      "0 Crime 0.12811694\n",
      "1 Documentary 0.04487312\n",
      "0 Drama 0.46571514\n",
      "0 Fantasy 0.07973188\n",
      "0 Film-Noir 0.01713556\n",
      "0 Horror 0.10158852\n",
      "0 Musical 0.039523125\n",
      "0 Mystery 0.060415536\n",
      "0 Romance 0.17461616\n",
      "0 Sci-Fi 0.09662956\n",
      "0 Thriller 0.20048127\n",
      "0 War 0.043530583\n",
      "0 Western 0.022641301\n",
      "--\n",
      "Movie: Stolen Summer\n",
      "0 Action 0.18963039\n",
      "0 Adventure 0.12896195\n",
      "0 Animation 0.05483353\n",
      "0 Children's 0.011578023\n",
      "0 Comedy 0.38233346\n",
      "0 Crime 0.12810895\n",
      "0 Documentary 0.044873238\n",
      "1 Drama 0.4657577\n",
      "0 Fantasy 0.07972631\n",
      "0 Film-Noir 0.017136157\n",
      "0 Horror 0.10159856\n",
      "0 Musical 0.039524794\n",
      "0 Mystery 0.060416818\n",
      "0 Romance 0.1746003\n",
      "0 Sci-Fi 0.09662768\n",
      "0 Thriller 0.2004984\n",
      "0 War 0.043533206\n",
      "0 Western 0.022641748\n",
      "--\n",
      "Movie: Revenge of the Nerds IV: Nerds in Love\n",
      "0 Action 0.1896162\n",
      "0 Adventure 0.12896287\n",
      "0 Animation 0.054836214\n",
      "0 Children's 0.011578023\n",
      "1 Comedy 0.38233557\n",
      "0 Crime 0.12811658\n",
      "0 Documentary 0.044873714\n",
      "0 Drama 0.46572453\n",
      "0 Fantasy 0.07972178\n",
      "0 Film-Noir 0.017135799\n",
      "0 Horror 0.10160267\n",
      "0 Musical 0.039524287\n",
      "0 Mystery 0.060416292\n",
      "1 Romance 0.17462248\n",
      "0 Sci-Fi 0.09663012\n",
      "0 Thriller 0.2004986\n",
      "0 War 0.043529935\n",
      "0 Western 0.0226414\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_input_fn(predict_x, num):\n",
    "    return  tf.data.Dataset.from_tensors(dict(predict_x))\n",
    "\n",
    "from tensorflow_core.estimator import inputs\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: predict_input_fn(predict_x, 100))\n",
    "#user movie \n",
    "for pred_dict, expec in zip(predictions, expected_df.as_matrix()):\n",
    "    expected, source, movie = expec\n",
    "    print(\"Movie: {0}\".format(movie))\n",
    "    for idx, label in enumerate(expected):\n",
    "        print(label, genres[idx], pred_dict[\"probabilities\"][idx])\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
